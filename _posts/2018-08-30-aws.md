---
layout: post
title: "Running a Docker Container on AWS EC2"
date: 2018-08-30
description: "How to set up an AWS account, launch an instance, run a docker container in that instance, and upload/download data to and from the container."
tags: [aws, docker]
published: false
---

Amazon Web Service's Elastic Compute Cloud (AWS EC2) is Amazon's cloud computing platform, which allows users to rent server time to run their own applications.  EC2 provides a selection of different hardware configurations (or [instance types](https://aws.amazon.com/ec2/instance-types/)), so customers can select the hardware configuration which best suits their needs.  For example, a scientific modelling application might use a compute-optimized EC2 instance; an in-memory database might use a memory-optimized EC2 instance; an application training deep neural networks might use an EC2 instance which has GPUs available to it; and a Hadoop application might use a storage-optimized EC2 instance.  This allows customers to rent a hardware environment which suits their needs without having to purchase that hardware up front. 

In this post, we'll see how to set everything up for a new AWS account, launch an instance, upload our data, run some python code on it, download the results, and shut down our instance.  

**Outline**

[TOC]

## Create an AWS Account

To run an EC2 instance, you'll first need an Amazon Web Services account.  You can sign up for a Free Tier account at the [AWS website](https://aws.amazon.com/) by clicking on the "Create an AWS Account" button and following the instructions.

## Create an IAM User

After creating an account, you should create an Identity and Access Management (IAM) user through which you can administrate your rented instances.

1. Sign in to the [IAM console](https://console.aws.amazon.com/iam/) using your AWS account information.
2. In the panel on the left, choose "Users", and then select the "Add user" button.
3. For the User name, enter "Administrator" (or whatever you want, really).
4. Select the "AWS Management Console access" checkbox.
5. Select the "Custom password" radio button and enter the password you'd like to use for this IAM user.
6. Unselect the "User must create a new password at next sign-in" checkbox (unless you're making the account for someone else, in which case this will enable them to set their own password).
7. Then select "Next: Permissions".
8. Select "Add user to group", and choose "Create group".
9. For the Group name, enter "Administrators" (or, again, whatever you want).
10. In the table of policies, select the check box next to the AdministratorAccess policy (with the description "Provides full access to AWS services").
11. Select "Create group".
12. Select the checkbox next to your newly-created group.
13. Select "Next: Review", and then "Create user".
14. You can now log out of the AWS console, and log back in as the IAM Administrator user you just created.   Go to `https://<your_aws_account_id>.signin.aws.amazon.com/console/`, where `<your_aws_account_id>` is your AWS account number without the hyphens.
15. Sign in using the IAM user username (`Administrator`), and the password you set for that user.

## Create a Key Pair 

To secure your connection to your instance, you'll want to create a cryptographic key pair.  This will allow you to connect to your instance using the private key via SSH.

1. Sign in to the [AWS EC2 console](https://console.aws.amazon.com/ec2/) using your IAM Administrator user information.
2. In the panel on the left, in the "NETWORK & SECURITY" section, select "Key Pairs".
3. In the upper-right, select the region (e.g. "US East (Ohio)" or "US West (Oregon)") for which you want to generate the key pair.  It's probably fine to leave it as is.  However, if you want to run an instance in different regions, you'll need to generate a new key pair for each region - key pairs are region-specific.
4. Click the blue "Create Key Pair" button.
5. Enter a name for your new key pair.  I'll refer to the name you chose below as `<key-pair-name>`. Amazon recommends using `<username>-key-pair-<region>`, where `<username>` is your IAM username (or some other name that you'll remember), and `<region>` is the AWS region you'll be connecting to (the region shown in the upper-right of the page).

The private key will be downloaded by your browser.  Open up a terminal and set user permissions for the file:

```bash
chmod 400 <key-pair-name>.pem
```

If you're in Windows, you can either use PuTTY (see the "To prepare to connect to a Linux instance from Windows using PuTTY" section of [this page](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html)), or personally I'd recommend using [cmder](http://cmder.net/), which comes with an SSH client and bash emulator which allows you to run that `chmod` command directly.

Save the private key file in a safe place, because you won't be able to download it again!  However, you can always create a new key pair when you launch an instance.

## Create a Security Group

You'll also want to create what's called a "security group", which sets limits on what kind of network traffic your instance can receive. 

1. From the upper-right of the [EC2 console](https://console.aws.amazon.com/ec2/), select the region for the security group you're about to create (e.g. "US East (Ohio)").  This should be the same region for which you created the key pair (and will probably already be set to the one you want).
2. In the panel on the left, under "NETWORK & SECURITY", select "Security Groups".
3. Click the blue "Create Security Group" button.
4. For the Security group name, enter a name for your new security group.  Amazon recommends `<name>_SG_<region>`, where `<name>` is some name you'll remember, and `<region>` is the AWS region for which you're creating the security group (because, like key pairs, security groups are region-specific).
5. Enter a description of your security group (e.g. "My default SG for Ohio")
6. In the "Inbound tab", create these three rules:

- Type=HTTP, Source=Anywhere
- Type=HTTPS, Source=Anywhere
- Type=SSH, Source="My IP"

These rules ensure that your instance will accept HTTP requests from any IP, but only SSH connections from the IP address of the computer you're currently using, which helps keep your instance secure.  You can of course change this to accept whatever IP addresses or range of addresses from which you want to connect to your instance.

Finally, click the blue "Create" button to create the security group.

## Launch an EC2 Instance

Now that we have things set up, we can launch our AWS virtual machine (called an "instance"). From the [EC2 console](https://console.aws.amazon.com/ec2/), click the blue "Launch Instance" button.

Select the Amazon Machine Image (AMI) you want to use.  If you want to ensure you're using only AMIs you won't be charged for, select the "Free tier only" checkbox on the left.  We'll use the "Amazon Linux 2" AMI.

Select the Instance Type you want and click the blue "Review and Launch" button.  For testing things out, you'll probably want to select the `t2.micro` instance type (which is free).   However, for running Featuretools you'll want to select an instance type which has enough memory.  Here's a list of [AWS instance types](https://aws.amazon.com/ec2/instance-types/) and their [pricing](https://aws.amazon.com/ec2/pricing/on-demand/).  To run Featuretools on the full dataset, we'll need far more memory than is available to a `t2.micro` instance, and so we'll use the `m5.4xlarge` instance type.

Note that the `m5.4xlarge` instance type is *not* free!  So don't launch an instance of that type just yet.  I'd suggest trying everything in this post out using the `t2.micro` instance first (which, again, is free), and then only once you know what you're doing going back and starting a paid instance.

Now we'll set our instance to belong to the security group we created earlier.  Under "Security Groups", click the "Edit security groups" link.

Select the "Select an existing security group" radio button, and select the box next to the security group you created earlier.  

If you'll want to connect to your instance from a different IP address than you were using when you set up the security group, you'll have to either edit your security group, or create a new security group which allows connections from your new IP. 

To create a new security group,

1. Select the "Create a new security group" radio button.
2. Give your new security group a name, if you want.
3. Enter the same three rules as above (Type=HTTP,Source=Anywhere; Type=HTTPS,Source=Anywhere; Type=SSH,Source=My IP) 

Or, to edit an existing security group (you only have to do this if you're connecting from a different IP than you were when you set up the security group)

1. Go back to the EC2 console and select "Security groups" from the panel on the left.
2. Select the box next to the security group you want to change.
3. Click the "Actions" button and select "Edit inbound rules".
4. Change the "Source" of the SSH rule to be "My IP".
5. Click the blue "Save" button.

After you've selected a security group (or created a new one), click the blue "Review and Launch" button.

Click the blue "Launch" button.

Here you can either select to use the key pair you created earlier, or create a new one (for example if you don't have access to the key pair you created earlier).  To use the key pair you created earlier, select "Choose an existing key pair" from the drop-down, and then select the name of the key-pair you want to use from the second drop-down.  But if you want to create a new one, select "Create a new key pair" from the drop-down, then give it a name, and select "Download Key Pair", and repeat the `chmod` command from earlier on the downloaded file.

Finally, click the acknowledgement checkbox and click the blue "Launch Instances" button.  From here you can click the blue "View Instances" button (or, from the EC2 console, go to "Instances" in the panel on the left).  From here you can see info about your instance which should now be up and running!

## Connect to an EC2 Instance

To connect to your AWS instance via SSH, run (in a terminal):

```bash
ssh -i <key-pair-name>.pem ec2-user@<publicDNS>
```

where `<publicDNS>` is the public DNS of your instance.  You can see the public DNS of your instance by going to the Instances page (in the EC2 console, in the panel on the left under "INSTANCES", click on "Instances"), and selecting the instance you want.  In the lower right of the page, in the "Description" tab, there will be a domain after "Public DNS (IPv4)", for example `ec2-99-999-99-99.us-east-2.compute.amazonaws.com`.  Use this as the `<publicDNS>` when logging in via SSH.

Again, if you're in windows, you'll have to use [Putty](https://www.putty.org/), [cmder](http://cmder.net/), or some other SSH client for windows.

## Install Docker, Build, and Run a Container

The next thing we'll want to do is start a [docker container](https://www.docker.com/) in which to run our code.  We'll use a docker container not only because they ensure reproducible execution of our code, but because it automates the installation of all the software we'll need.

We'll use the `yum` package manager to install docker.  First update `yum` by running (within your shell after SSH-ing into your instance):

```bash
sudo yum update -y
```

Then install docker with:

```bash
sudo yum install -y docker
```

And then start the docker service:

```bash
sudo service docker start
```

Finally, set the user permissions so you don't have to type `sudo` before every command...

```bash
sudo usermod -a -G docker ec2-user
```

Log out and log back in again to your instance (type `exit` and then log back in with `ssh -i <key-pair-name>.pem ec2-user@<publicIP>`).

Make sure docker has started up successfully by running the following command, which should show information about local or running docker images:

```bash
docker info
```

Now you can either create new docker image from scratch, or run one that's already been created.  To run a docker container from [Docker Hub](https://hub.docker.com/) (the docker equivalent of GitHub), run:

```bash
docker run -it <owner>/<image>
```

Where `<owner>` is the owner on Dockerhub of the image you want to run, and `<image>` is the image's name.  The command will automatically download and run a docker image from Docker Hub.  The `i` and `t` options cause the docker image to run in interactive mode, and you will get dropped into a console within the container.  For example, to use [Kaggle's docker image for Python](https://hub.docker.com/r/kaggle/python/), run (though note that this won't work on a `t2.micro` instance because it doesn't have enough memory!):

```bash
docker run -it kaggle/python
```

To use the image we'll be building below, you can run the image from my Docker Hub repository:

```
docker run -it winsto99/featuretools
```

You can also create your own docker image from scratch!  To run automated feature engineering with featuretools, we'll  only need numpy, pandas, and featuretools (and their dependencies).  So, we can build a relatively simple Dockerfile:

````dockerfile
FROM ubuntu:latest

RUN apt-get update
RUN apt-get install -y python3 python3-pip

RUN pip3 install numpy \
    pandas \
    featuretools
````

Save the above code to a file called `Dockerfile`.

To build the docker image from that Dockerfile (if it's the only file named `Dockerfile` in your current directory), run

```bash
docker build -t <image-name> .
```

where `<image-name>` is the name you want to give your docker image (for example, `featuretools`).  

If you have multiple docker files with different file names in the same directory, you can build a specific one by piping that file into the build command:

```bash
docker build -t <image-name> - < <dockerfile-name>
```

where `<dockerfile-name>` is the filename of the dockerfile you want to build.

You can see all the images you have built or downloaded to your instance by running

```bash
docker images
```

You can now push the docker image to your docker hub repository.  This both makes it easier for you to use it in the future (you can just `docker pull` the image instead of building it from scratch), and also makes it easy for you to share the image with others (they can just `docker pull` the image).  If you don't have a docker hub account, you can head over to the [Docker Hub](https://hub.docker.com/) website and create a free account.

Back at your EC2 instance shell, log in to your docker hub account by running

```bash
docker login
```

And entering your docker hub username and password.

Then, tag your image with 

```bash
docker tag <image-name> <username>/<image-name>
```

Where `<username>` is your docker hub username, and `<image-name>` is the name of the image you want to push to docker hub.

Finally, you can push your image to docker hub with

```bash
docker push <username>/<image-name>
```

To run that image that you built, run:

```bash
docker run -it <image-name>
```

Or, if you haven't built the image on this instance but you've previously pushed it to Docker Hub, run:

```bash
docker run -it <username>/<image-name>
```

Now you've been dropped into a bash shell running in your Docker container!

**TODO**: though maybe should do via ECS...

## Upload Data to an EC2 Instance

Now you need to copy your data from your local machine (or wherever) to your EC2 instance.  Transfer data from your local machine to your home folder on your AWS instance with

```bash
scp -i <key-pair-name>.pem <filename> ec2-user@<publicDNS>:~/
```

where `<filename>` is the file you want to transfer.

But then the data is only on your virtual machine, but not within the docker container!  To copy data to a inside a running docker container, SSH into your instance and run

```bash
docker cp <filename> <container_name>:/desired/path/<filename>
```

where `<filename>` is the file name of the data you want to transfer, `/desired/path` is the path within your docker container where you want the data to be copied to, and `<container_name>` is the name of the running container.  You can see information about running containers by running

```bash
docker ps
```

The value in the "NAMES" column is what you want to use for the `<container_name>`.   Docker comes up with some... [interesting default names](https://github.com/moby/moby/blob/master/pkg/namesgenerator/names-generator.go) for containers, like "peaceful_wozniak" and "hopeful_heisenburg".  If you don't like using the randomly-generated names, you could have given your container your own name by specifying the `--name <custom_name>` argument when running `docker run`.

However, instead of uploading data from your computer and then copying it to the container, it's usually easier and faster to just transfer the data from within the docker container directly.  Either by reading from an S3 bucket, scp-ing from within the running container, or some other method.  

For example, if you want to download the data for a Kaggle competition, you can copy your Kaggle API token `kaggle.json` to your EC2 instance, copy it to inside the container (see [the Kaggle API page](https://github.com/Kaggle/kaggle-api) about getting that set up if you're interested), installing Kaggle with

```bash
pip3 install kaggle
```

And then downloading the data via the Kaggle CLI with

```bash
kaggle competitions download -c <competition-name>
```

or

```bash
kaggle datasets download -d <username>/<dataset_name>
```

depending on what you want to download.

## Run Code on an EC2 Instance 

**TODO**: how to run python code or run a jupyter notebook from the instance  (really you'd just want to use jupyters image for that tho)

## Download Data from an AWS Instance

**TODO**: again either scp or aws cli

## Shut Down an AWS Instance

When you're done using your instance, you should terminate it.  With a free tier instance, this is both polite and practical - you won't be able to launch another free tier instance until you've terminated the one you have running (i.e., you are only allowed to have one running free tier instance at any given time).

This is more important when using a non-free-tier instance because *you're getting charged for each second the instance runs!* 

To shut down an instance, go to the EC2 console. 

In the panel on the left, under "INSTANCES", select "Instances".

Select the box next to the instance you wish to terminate.

Click the "Actions" button at the top, and select "Instance State" -> "Terminate".

A confirmation dialog will pop up, and hit the blue "Yes, Terminate" button to end the instance.

## Conclusion

**TODO**: what you can do with it, eg featuretools, deep learning etc

Also, for further reading, Amazon has guides which cover some of the information in this post.

- [Setting Up with Amazon EC2](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html)
- [Getting Started with Amazon EC2 Linux Instances](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html)
- [How to Deploy Docker Containers on AWS](https://aws.amazon.com/getting-started/tutorials/deploy-docker-containers/)